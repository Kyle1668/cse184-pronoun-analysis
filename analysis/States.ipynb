{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the state breakdown of the gendered phrases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "masculine_themed_wording = [\n",
    "    \"competitive\",\n",
    "    \"dominate\",\n",
    "    \"leader\",\n",
    "    \"rock star\",\n",
    "    \"rockstar\",\n",
    "    \"guru\",\n",
    "    \"ninja\",\n",
    "    \"hacker\",\n",
    "    \"superhero\",\n",
    "    \"prove themselves\",\n",
    "    \"analyze\",\n",
    "    \"determine\",\n",
    "    \"crush it\",\n",
    "    \"world class\",\n",
    "    \"superior\",\n",
    "    \"ambitious\",\n",
    "    \"aggressive\",\n",
    "    \"leader\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv(\"../data/dice/us-technology-jobs-on-dicecom/dice_com-job_us_sample.csv\")\n",
    "data_set = data_set.get(['jobtitle','jobdescription','joblocation_address'])\n",
    "states = pd.read_csv(\"states.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['State'] = data_set['joblocation_address'].apply(lambda x: pd.Series(str(x).split(\", \")[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptionDict = createTokenizedJobDescriptionDict(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numOfOcurrences(tokenizedPhrase, tokenizedDescription): \n",
    "#     counter = 0\n",
    "    # if its a phrase just look for the exact phrase in the description otherwise look at the stem of the words\n",
    "#     if len(word_tokenize(phrase)) > 1: \n",
    "#         regex = re.compile(phrase)\n",
    "#         return len(re.findall(regex, description))\n",
    "    \n",
    "#     desc = word_tokenize(description) \n",
    "#     desc = list(map(lambda x: ps.stem(x), desc))\n",
    "#     return desc.count(stem)\n",
    "\n",
    "    counter = 0\n",
    "    i = len(tokenizedPhrase)\n",
    "    for x in range(len(tokenizedDescription)-i + 1):\n",
    "        if tokenizedDescription[x:x+i] == tokenizedPhrase:\n",
    "            counter += 1; \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(s): \n",
    "    ps = PorterStemmer()\n",
    "    tokens = word_tokenize(s)\n",
    "    stem = list(map(lambda x : ps.stem(x), tokens))\n",
    "    \n",
    "    return stem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicesOfJobsWithPhrase(phrase, df, descriptionDict): \n",
    "    indices = []\n",
    "    for index, row in df.iterrows(): \n",
    "        tokenizedPhrase = stem_tokens(phrase)\n",
    "#         tokenizedDesc = stem_tokens(row.get(\"jobdescription\"))\n",
    "        if numOfOcurrences(tokenizedPhrase, descriptionDict[index]) > 0: \n",
    "            indices.append(index)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTokenizedJobDescriptionDict(df): \n",
    "    descriptions = {}\n",
    "    for index, row in df.iterrows(): \n",
    "        descriptions[index] = stem_tokens(row.get(\"jobdescription\"))\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeStateInfo(state, full_df,descriptions): \n",
    "    stateInfo = {}\n",
    "    stateInfo['region'] = state\n",
    "    stateInfo['word_count'] = {}\n",
    "    state_df = full_df.where(full_df['State'] == state).dropna()\n",
    "    biasedIndices = []; \n",
    "    \n",
    "    for word in masculine_themed_wording: \n",
    "        \n",
    "        indices = indicesOfJobsWithPhrase(word, state_df, descriptions)\n",
    "        stateInfo['word_count'][word] = len(indices)\n",
    "        biasedIndices += indices\n",
    "    \n",
    "    topWords = [item[0] for item in reversed(sorted(stateInfo['word_count'].items(), key = lambda kv: kv[1]))][:5]\n",
    "    \n",
    "    stateInfo['numberOfJobsInDataSet'] = len(state_df)\n",
    "    stateInfo['numberOfBiasedJobs'] = len(set(biasedIndices))\n",
    "    try: \n",
    "        stateInfo['percentageOfBiasedJobs'] = float(stateInfo['numberOfBiasedJobs']/ stateInfo['numberOfJobsInDataSet']) * 100\n",
    "    except ZeroDivisionError: \n",
    "        stateInfo['percentageOfBiasedJobs'] = 'NA'\n",
    "        #     stateInfo['biasedIndices'] = list(set(biasedIndices))\n",
    "                                                                                                               \n",
    "    stateInfo['questionFour'] = topWords\n",
    "    del(stateInfo['word_count'])\n",
    "    return stateInfo\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportInfo(DF): \n",
    "    data = [computeStateInfo(state, DF,descriptionDict) for state in states['Code']]\n",
    "    stateData = {\"data\": data}; \n",
    "    with open('stateData.json', 'w') as outfile:\n",
    "        json.dump(stateData, outfile)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124.61947178840637"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "startTime = time.time()\n",
    "exportInfo(data_set)\n",
    "runtime = time.time() - startTime\n",
    "runtime"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
